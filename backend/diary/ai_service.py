# diary/ai_service.py (ìƒˆ í•¨ìˆ˜ ì¶”ê°€)
import openai
import logging
from datetime import datetime
from django.conf import settings
import google.generativeai as genai
from django.conf import settings

logger = logging.getLogger('diary')

class ImageGenerator:
    # ê°ì •ë³„ ìŠ¤íƒ€ì¼ ë§¤í•‘
    EMOTION_STYLES = {
        'happy': 'Vibrant colors, bright lighting, Impressionist style, cheerful atmosphere',
        'sad': 'Muted colors, watercolor style, rainy or foggy atmosphere, minimalist',
        'angry': 'Intense colors, bold brush strokes, Abstract Expressionism, dynamic composition',
        'anxious': 'Surrealist style, dreamlike, slightly distorted, soft edges',
        'peaceful': 'Pastel colors, soft lighting, realistic landscape, serene atmosphere',
        'excited': 'Vivid colors, Pop Art style, dynamic energy, high contrast',
        'tired': 'Low saturation, soft focus, cozy atmosphere, warm lighting',
        'love': 'Warm colors, romantic atmosphere, soft glow, detailed',
    }

    def generate(self, diary_content, emotion=None):
        """
        Gemini Imagen 3ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê¸° ë‚´ìš©ì— ë§ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            diary_content (str): ì¼ê¸° ë‚´ìš©
            emotion (str, optional): ì¼ê¸°ì˜ ê°ì • (happy, sad, etc.)
            
        Returns:
            dict: { 'url': ..., 'prompt': ... }
        """
        import os
        import uuid
        import base64
        from django.core.files.base import ContentFile
        from django.core.files.storage import default_storage
        
        logger.debug(f"Generating image for: {diary_content[:50]}...")
        
        if not settings.GEMINI_API_KEY:
            logger.error("Gemini API Key is not configured for Image Generation.")
            raise ValueError("API Key Configuration Error")

        try:
            # ê°ì •ì— ë”°ë¥¸ ìŠ¤íƒ€ì¼ ì„ íƒ
            style_instruction = self.EMOTION_STYLES.get(emotion, "Artistic and emotional illustration")
            
            # AIê°€ ìƒì„±í•  ì´ë¯¸ì§€ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
            
            # ì˜ì–´ ë²ˆì—­ì´ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, ì¼ë‹¨ ë‹¨ìˆœ ê²°í•©
            prompt = (
                f"An emotional illustration representing the following diary content. "
                f"Style: {style_instruction}. "
                f"Diary snippet: '{diary_content[:300]}'"
            )
            
            # Gemini ëª¨ë¸ (ì˜ˆ: gemini-3-pro-image-preview) ì‚¬ìš© ì‹œ
            if settings.GEMINI_IMAGE_MODEL.lower().startswith('gemini'):
                import google.generativeai as genai
                if settings.GEMINI_API_KEY:
                    genai.configure(api_key=settings.GEMINI_API_KEY)
                
                gen_model = genai.GenerativeModel(settings.GEMINI_IMAGE_MODEL)
                
                # Gemini 3 Image Generation Prompt
                response = gen_model.generate_content(
                    f"Draw the following: {prompt}",
                    # safety_settings? generation_config?
                )
                
                # ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ (Gemini 3ëŠ” partsì— infoê°€ ìˆìŒ)
                # ì£¼ì˜: SDK ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ. ë³´í†µ response.parts[0].inline_data
                if not response.parts:
                     raise ValueError("No content generated")
                
                image_data = None
                for part in response.parts:
                    if part.inline_data:
                        image_data = part.inline_data.data # bytes
                        break
                
                if not image_data:
                    raise ValueError("No image data found in Gemini response")

            else:
                # ê¸°ì¡´ Imagen REST API í˜¸ì¶œ (imagen-*)
                import requests
                
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{settings.GEMINI_IMAGE_MODEL}:predict?key={settings.GEMINI_API_KEY}"
                
                headers = {
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "instances": [
                        {
                            "prompt": prompt
                        }
                    ],
                    "parameters": {
                        "sampleCount": 1,
                        "aspectRatio": "1:1",
                        # "safetyFilterLevel": "block_some", 
                        # "personGeneration": "allow_adult"
                    }
                }
                
                response = requests.post(url, headers=headers, json=payload)
                response.raise_for_status()
                
                result = response.json()
                
                # ì‘ë‹µ êµ¬ì¡°: {'predictions': [{'bytesBase64Encoded': '...'}]}
                if 'predictions' not in result or not result['predictions']:
                    logger.error(f"Imagen API Error: {result}")
                    raise ValueError("No images generated by Gemini (Imagen).")
                    
                b64_image = result['predictions'][0]['bytesBase64Encoded']
                image_data = base64.b64decode(b64_image)
            
            # ê³µí†µ: ì´ë¯¸ì§€ ë¡œì»¬ ì €ì¥
            filename = f"ai_images/{datetime.now().strftime('%Y/%m/%d')}/{uuid.uuid4()}.png"
            
            # ì„ì‹œ íŒŒì¼ ê²½ë¡œ
            temp_path = os.path.join(settings.MEDIA_ROOT, filename)
            os.makedirs(os.path.dirname(temp_path), exist_ok=True)
            
            with open(temp_path, "wb") as f:
                f.write(image_data)
            
            # URL ìƒì„±
            image_url = settings.MEDIA_URL + filename
            image_url = image_url.replace('\\', '/')
            
            logger.info(f"Image generated and saved successfully: {image_url}")
            
            return {
                'url': image_url,
                'prompt': prompt
            }
            
                
        except Exception as e:
            # í†µí•©ëœ ì—ëŸ¬ ì²˜ë¦¬ ë° Fallback ë¡œì§
            error_msg = str(e)
            if isinstance(e, requests.exceptions.HTTPError):
                error_msg = f"HTTP Error: {e.response.text}"
                
            logger.error(f"Gemini (Imagen) Image Generation failed: {error_msg}")
            logger.info("Falling back to OpenAI DALL-E...")
            
            if not settings.OPENAI_API_KEY:
                # Fallback ë¶ˆê°€ëŠ¥ ì‹œ ì›ë³¸ ì—ëŸ¬ ë‹¤ì‹œ ë°œìƒ (í˜¹ì€ ìƒˆ ì—ëŸ¬)
                raise e
            
            try:
            # DALL-E Fallback (OpenAI v1.x)
            import openai
            import requests
            client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)


class KeywordExtractor:
    """
    KeyBERT ë°©ì‹ì˜ í‚¤ì›Œë“œ ì¶”ì¶œê¸°
    - ë¬¸ì„œë¥¼ n-gramìœ¼ë¡œ ë¶„í• 
    - ë¬¸ì„œì™€ n-gramì˜ ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°
    - ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ í‚¤ì›Œë“œ(êµ¬) ì¶”ì¶œ
    """
    
    def __init__(self):
        try:
            from sentence_transformers import SentenceTransformer
            # ChatServiceì™€ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš© (ë©”ëª¨ë¦¬ íš¨ìœ¨)
            self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        except ImportError:
            logger.warning("sentence-transformers not installed. Keyword extraction disabled.")
            self.model = None

    def extract_keywords(self, text, top_n=5, keyphrase_ngram_range=(1, 2)):
        """
        í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ/êµ¬ ì¶”ì¶œ
        """
        if not self.model or not text or len(text) < 10:
            return []
            
        try:
            from sklearn.feature_extraction.text import CountVectorizer
            from sklearn.metrics.pairwise import cosine_similarity
            
            # 1. n-gram í›„ë³´ ìƒì„±
            count = CountVectorizer(ngram_range=keyphrase_ngram_range, stop_words=None).fit([text])
            candidates = count.get_feature_names_out()

            # 2. ë¬¸ì„œ ë° í›„ë³´ ì„ë² ë”©
            doc_embedding = self.model.encode([text])
            candidate_embeddings = self.model.encode(candidates)

            # 3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            distances = cosine_similarity(doc_embedding, candidate_embeddings)
            
            # 4. ìƒìœ„ nê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = []
            for index in distances.argsort()[0][-top_n:]:
                keywords.append(candidates[index])
            
            # ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (argsortëŠ” ì˜¤ë¦„ì°¨ìˆœì´ë¯€ë¡œ ë’¤ì§‘ìŒ)
            return keywords[::-1]
            
        except Exception as e:
            logger.error(f"Keyword extraction failed: {e}")
            return []

            
            response = client.images.generate(
                model="dall-e-3",
                prompt=prompt,
                size="1024x1024",
                quality="standard",
                n=1,
            )
            
            dall_e_url = response.data[0].url
            
            # Download DALL-E image to save locally (to keep architecture consistent)
            img_data = requests.get(dall_e_url).content
                
                filename = f"ai_images/{datetime.now().strftime('%Y/%m/%d')}/{uuid.uuid4()}.png"
                temp_path = os.path.join(settings.MEDIA_ROOT, filename)
                os.makedirs(os.path.dirname(temp_path), exist_ok=True)
                
                with open(temp_path, "wb") as f:
                    f.write(img_data)
                
                image_url = settings.MEDIA_URL + filename
                image_url = image_url.replace('\\', '/')
                
                logger.info(f"Fallback Image generated and saved successfully: {image_url}")
                
                return {
                    'url': image_url,
                    'prompt': prompt
                }
                
            except Exception as openai_error:
                logger.error(f"OpenAI Fallback failed: {openai_error}")
                # ì›ë³¸ ì—ëŸ¬ì™€ Fallback ì—ëŸ¬ ëª¨ë‘ ë¡œê¹…ë˜ì—ˆìœ¼ë¯€ë¡œ, ì›ë³¸ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ê±°ë‚˜
                # ì‚¬ìš©ìì—ê²Œ ëª…í™•í•œ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•˜ê¸° ìœ„í•´ ValueError ë°œìƒ
                raise ValueError(f"Primary (Gemini) failed: {error_msg}. Fallback (OpenAI) failed: {openai_error}")

class SpeechToText:
    """
    OpenAI Whisper APIë¥¼ ì‚¬ìš©í•œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ì„œë¹„ìŠ¤.
    100ê°œ ì´ìƒì˜ ì–¸ì–´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
    """
    
    # ì§€ì›ë˜ëŠ” ì£¼ìš” ì–¸ì–´ ëª©ë¡ (ISO 639-1 ì½”ë“œ)
    SUPPORTED_LANGUAGES = {
        'ko': 'í•œêµ­ì–´',
        'en': 'English',
        'ja': 'æ—¥æœ¬èª',
        'zh': 'ä¸­æ–‡',
        'es': 'EspaÃ±ol',
        'fr': 'FranÃ§ais',
        'de': 'Deutsch',
        'pt': 'PortuguÃªs',
        'it': 'Italiano',
        'ru': 'Ğ ÑƒÑÑĞºĞ¸Ğ¹',
        'ar': 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©',
        'hi': 'à¤¹à¤¿à¤¨à¥à¤¦à¥€',
        'th': 'à¹„à¸—à¸¢',
        'vi': 'Tiáº¿ng Viá»‡t',
    }
    
    def transcribe(self, audio_file, language='ko'):
        """
        ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            audio_file: ì˜¤ë””ì˜¤ íŒŒì¼ ê°ì²´ (mp3, mp4, mpeg, mpga, m4a, wav, webm ì§€ì›)
            language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: 'ko' í•œêµ­ì–´)
                     Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ìë™ ê°ì§€
        
        Returns:
            dict: {
                'text': ë³€í™˜ëœ í…ìŠ¤íŠ¸,
                'language': ì‚¬ìš©ëœ ì–¸ì–´ ì½”ë“œ
            }
        """
        logger.debug(f"Transcribing audio with language: {language}")
        
        try:
            # OpenAI Whisper API í˜¸ì¶œ
            transcription_params = {
                'model': 'whisper-1',
                'file': audio_file,
            }
            
            # ì–¸ì–´ê°€ ì§€ì •ëœ ê²½ìš°ì—ë§Œ language íŒŒë¼ë¯¸í„° ì¶”ê°€
            # (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ Whisperê°€ ìë™ ê°ì§€)
            if language:
                transcription_params['language'] = language
            
            response = openai.Audio.transcribe(**transcription_params)
            
            text = response.text if hasattr(response, 'text') else response['text']
            
            logger.info(f"Audio transcribed successfully. Length: {len(text)} characters")
            
            return {
                'text': text,
                'language': language or 'auto-detected'
            }
            
        except Exception as e:
            logger.error(f"OpenAI API error during transcription: {e}")
            raise e
        except Exception as e:
            logger.error(f"An unexpected error occurred during transcription: {e}")
            raise e
    
    def translate_to_english(self, audio_file):
        """
        ë¹„ì˜ì–´ ìŒì„±ì„ ì˜ì–´ í…ìŠ¤íŠ¸ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.
        
        Args:
            audio_file: ì˜¤ë””ì˜¤ íŒŒì¼ ê°ì²´
        
        Returns:
            dict: {
                'text': ì˜ì–´ë¡œ ë²ˆì—­ëœ í…ìŠ¤íŠ¸,
                'original_language': ì›ë³¸ ì–¸ì–´ (ìë™ ê°ì§€)
            }
        """
        logger.debug("Translating audio to English")
        
        try:
            response = openai.Audio.translate(
                model='whisper-1',
                file=audio_file,
            )
            
            text = response.text if hasattr(response, 'text') else response['text']
            
            logger.info(f"Audio translated successfully. Length: {len(text)} characters")
            
            return {
                'text': text,
                'original_language': 'auto-detected'
            }
            
        except Exception as e:
            logger.error(f"OpenAI API error during transcription: {e}")
            raise e
        except Exception as e:
            logger.error(f"An unexpected error occurred during translation: {e}")
            raise e
    
    @classmethod
    def get_supported_languages(cls):
        """ì§€ì›ë˜ëŠ” ì£¼ìš” ì–¸ì–´ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return cls.SUPPORTED_LANGUAGES


class DiarySummarizer:
    """
    ì¼ê¸° ë‚´ìš©ì„ AIë¡œ ìš”ì•½í•˜ëŠ” ì„œë¹„ìŠ¤
    GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê¸° ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•©ë‹ˆë‹¤.
    """
    
    def summarize(self, content: str, style: str = 'default') -> dict:
        """
        ì¼ê¸° ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤. (Gemini 1.5 Flash ì‚¬ìš©)
        
        Args:
            content: ì›ë³¸ ì¼ê¸° ë‚´ìš©
            style: ìš”ì•½ ìŠ¤íƒ€ì¼ 
                - 'default': ê¸°ë³¸ 3ì¤„ ìš”ì•½
                - 'short': 1ì¤„ ìš”ì•½
                - 'bullet': í•µì‹¬ í¬ì¸íŠ¸ ë¶ˆë¦¿
        
        Returns:
            dict: {
                'summary': ìš”ì•½ëœ ë‚´ìš©,
                'original_length': ì›ë³¸ ê¸€ì ìˆ˜,
                'summary_length': ìš”ì•½ ê¸€ì ìˆ˜,
                'style': ì‚¬ìš©ëœ ìŠ¤íƒ€ì¼
            }
        """
        logger.debug(f"Summarizing diary content with style: {style}")
        
        if not content or len(content.strip()) < 10:
            return {
                'summary': content,
                'original_length': len(content),
                'summary_length': len(content),
                'style': style,
                'error': 'ìš”ì•½í•˜ê¸°ì— ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.'
            }
        
        # ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        style_prompts = {
            'default': """ë‹¤ìŒ ì¼ê¸° ë‚´ìš©ì„ 3ì¤„ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
- í•µì‹¬ ë‚´ìš©ê³¼ ê°ì •ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
- ì¼ê¸°ì˜ ë¶„ìœ„ê¸°ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”.
- ìš”ì•½ë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.""",
            
            'short': """ë‹¤ìŒ ì¼ê¸° ë‚´ìš©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì•„ì£¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
- ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”.
- ìš”ì•½ë§Œ ë°˜í™˜í•˜ì„¸ìš”.""",
            
            'bullet': """ë‹¤ìŒ ì¼ê¸° ë‚´ìš©ì˜ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ë¶ˆë¦¿ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
- 3-5ê°œì˜ í•µì‹¬ í¬ì¸íŠ¸
- ê° í¬ì¸íŠ¸ëŠ” ê°„ê²°í•˜ê²Œ
- "â€¢ " ê¸°í˜¸ë¡œ ì‹œì‘í•˜ì„¸ìš”."""
        }
        
        prompt_instruction = style_prompts.get(style, style_prompts['default'])
        
        if not settings.GEMINI_API_KEY:
            logger.error("Gemini API Key is not configured.")
            return {
                'summary': "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ìš”ì•½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                'original_length': len(content),
                'summary_length': 0,
                'style': style,
                'error': 'Configuration Error'
            }

        try:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            model = genai.GenerativeModel(settings.GEMINI_TEXT_MODEL)
            
            response = model.generate_content([
                {'role': 'user', 'parts': [f"{prompt_instruction}\n\nì¼ê¸° ë‚´ìš©:\n{content}"]}
            ])
            
            summary = response.text.strip()
            
            logger.info(f"Diary summarized successfully. Original: {len(content)} chars, Summary: {len(summary)} chars")
            
            return {
                'summary': summary,
                'original_length': len(content),
                'summary_length': len(summary),
                'style': style
            }
            
        except Exception as e:
            logger.error(f"Gemini API error during summarization: {e}")
            # ì—ëŸ¬ ë°œìƒ ì‹œ ì›ë³¸ ë‚´ìš©ì„ "ìš”ì•½ ì‹¤íŒ¨" ë©”ì‹œì§€ì™€ í•¨ê»˜ ë°˜í™˜í•˜ê±°ë‚˜ ì˜ˆì™¸ ì²˜ë¦¬
            return {
                'summary': "ìš”ì•½ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                'original_length': len(content),
                'summary_length': 0,
                'style': style,
                'error': str(e)
            }
    
    def suggest_title(self, content: str) -> str:
        """
        ì¼ê¸° ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì œëª©ì„ ì œì•ˆí•©ë‹ˆë‹¤.
        
        Args:
            content: ì¼ê¸° ë‚´ìš©
            
        Returns:
            str: ì œì•ˆëœ ì œëª©
        """
        logger.debug("Suggesting title for diary content")
        
        if not content or len(content.strip()) < 10:
            return "ì˜¤ëŠ˜ì˜ ì¼ê¸°"
        
        try:
            model = genai.GenerativeModel(settings.GEMINI_TEXT_MODEL)
            
            prompt = f"""ì¼ê¸° ë‚´ìš©ì„ ë³´ê³  ì ì ˆí•œ ì œëª©ì„ ì œì•ˆí•´ì£¼ì„¸ìš”. 
ë‚´ìš©: {content[:500]}
ê·œì¹™: ì œëª©ë§Œ ë°˜í™˜í•˜ì„¸ìš”. 15ì ì´ë‚´ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ë¥¸ ë§ì€ í•˜ì§€ ë§ˆì„¸ìš”."""
            
            response = model.generate_content(prompt)
            title = response.text.strip()
            # ë”°ì˜´í‘œ ì œê±°
            title = title.strip('"\'')
            
            logger.info(f"Title suggested: {title}")
            return title
            
        except Exception as e:
            logger.error(f"Error suggesting title: {e}")
            return "ì˜¤ëŠ˜ì˜ ì¼ê¸°"

    def generate_report_insight(self, diaries, period_label):
        """
        Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê¸° ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•© ê°ì • ë¦¬í¬íŠ¸(ì¸ì‚¬ì´íŠ¸)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            diaries (list): Diary QuerySet or list of Diary objects
            period_label (str): 'ì¼ì£¼ì¼' or 'í•œ ë‹¬'
            
        Returns:
            str: AI Insight text
        """
        if not diaries:
            return f"ì´ë²ˆ {period_label} ê¸°ë¡ëœ ì¼ê¸°ê°€ ì—†ì–´ì„œ ë¶„ì„í•´ë“œë¦´ ë‚´ìš©ì´ ì—†ì–´ìš”. ğŸ˜¢"

        if not settings.GEMINI_API_KEY:
            return "AI ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (API Key Missing)"

        # 1. ì¼ê¸° ë°ì´í„° í…ìŠ¤íŠ¸í™”
        diary_summaries = []
        for d in diaries:
            emotion = d.emotion if d.emotion else "Unknown"
            date = d.created_at.strftime("%Y-%m-%d")
            # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¦„
            content_snippet = d.content[:200]
            diary_summaries.append(f"[{date}] (Emotion: {emotion}) {content_snippet}")
        
        prompt_context = "\n".join(diary_summaries)
        
        system_prompt = f"""
You are a professional counselor and warm-hearted listener.
Analyze the user's diary entries for the past {period_label}.
Provide a summary of their emotional flow and a helpful, empathetic piece of advice.
Write in Korean, using a gentle and polite tone (í•´ìš”ì²´).
Keep the response under 300 characters.

User's Diaries:
{prompt_context}
"""
        
        try:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            model = genai.GenerativeModel(settings.GEMINI_TEXT_MODEL)
            response = model.generate_content(system_prompt)
            return response.text.strip()
            
        except Exception as e:
            logger.error(f"Generate Report Insight Error: {e}")
            return f"ì´ë²ˆ {period_label}ì˜ ê°ì • íë¦„ì„ ë¶„ì„í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."


class TemplateGenerator:
    """
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê¸° í…œí”Œë¦¿ì„ ìƒì„±í•˜ëŠ” ì„œë¹„ìŠ¤.
    ì‚¬ìš©ìê°€ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ ë§ì¶¤í˜• í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    def generate(self, topic: str, style: str = 'default') -> dict:
        """
        ì£¼ì œì— ë§ëŠ” ì¼ê¸° í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            topic: í…œí”Œë¦¿ ì£¼ì œ (ì˜ˆ: "ë…ì„œ ì¼ê¸°", "ìš”ë¦¬ ê¸°ë¡")
            style: ìŠ¤íƒ€ì¼ (default, simple, detailed)
            
        Returns:
            dict: {
                'name': í…œí”Œë¦¿ ì´ë¦„,
                'emoji': í…œí”Œë¦¿ ì•„ì´ì½˜,
                'description': í…œí”Œë¦¿ ì„¤ëª…,
                'content': í…œí”Œë¦¿ ë‚´ìš©
            }
        """
        logger.debug(f"Generating template for topic: {topic}, style: {style}")
        
        if not topic or len(topic.strip()) < 2:
            raise ValueError("ì£¼ì œë¥¼ 2ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        style_instruction = {
            'default': 'ì ë‹¹í•œ ê¸¸ì´ë¡œ ì‘ì„±í•˜ì„¸ìš”.',
            'simple': 'ê°„ë‹¨í•˜ê³  ì§§ê²Œ ì‘ì„±í•˜ì„¸ìš”. 3-4ê°œ í•­ëª©ë§Œ í¬í•¨í•˜ì„¸ìš”.',
            'detailed': 'ìì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ì–‘í•œ í•­ëª©ì„ í¬í•¨í•˜ì„¸ìš”.',
        }.get(style, 'ì ë‹¹í•œ ê¸¸ì´ë¡œ ì‘ì„±í•˜ì„¸ìš”.')
        
        try:
            model = genai.GenerativeModel(settings.GEMINI_TEXT_MODEL)
            
            prompt = f"""ë‹¹ì‹ ì€ ì¼ê¸° í…œí”Œë¦¿ì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì£¼ì œì— ë§ëŠ” ì¼ê¸° í…œí”Œë¦¿ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ì£¼ì œ: {topic}
ìš”êµ¬ì‚¬í•­: {style_instruction}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "name": "í…œí”Œë¦¿ ì´ë¦„ (ìµœëŒ€ 15ì)",
    "emoji": "ëŒ€í‘œ ì´ëª¨ì§€ 1ê°œ",
    "description": "í…œí”Œë¦¿ ì„¤ëª… (ìµœëŒ€ 50ì)",
    "content": "í…œí”Œë¦¿ ë‚´ìš© (ì¤„ë°”ê¿ˆ í¬í•¨)"
}}

í…œí”Œë¦¿ ë‚´ìš© ê·œì¹™:
- ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ê° ì„¹ì…˜ì„ êµ¬ë¶„í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ ì±„ìš¸ ë¶€ë¶„ì€ ë¹ˆ ì¤„ë¡œ ë‚¨ê²¨ë‘ì„¸ìš”
- í•­ëª©ì€ ì§ˆë¬¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”"""

            response = model.generate_content(prompt)
            content = response.text.strip()
            
            # JSON íŒŒì‹±
            import json
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if content.startswith('```'):
                content = content.split('```')[1]
                if content.startswith('json'):
                    content = content[4:]
            elif content.startswith('```json'): # Additional safe guard
                content = content[7:]

            content = content.strip()
            if content.endswith('```'):
                content = content[:-3].strip()
            
            result = json.loads(content)
            
            # ìœ íš¨ì„± ê²€ì‚¬
            required_keys = ['name', 'emoji', 'description', 'content']
            for key in required_keys:
                if key not in result:
                    raise ValueError(f"Missing key: {key}")
            
            logger.info(f"Template generated: {result['name']}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            # í´ë°±: ê¸°ë³¸ í…œí”Œë¦¿ ë°˜í™˜
            return {
                'name': topic[:15],
                'emoji': 'ğŸ“',
                'description': f'{topic} ì¼ê¸°ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤',
                'content': f'{topic}\n\nì˜¤ëŠ˜ì˜ ê¸°ë¡:\n\n\nëŠë‚€ ì :\n\n\në‚´ì¼ í•  ê²ƒ:\n'
            }
            
        except Exception as e:
            logger.error(f"Error generating template: {e}")
            raise e

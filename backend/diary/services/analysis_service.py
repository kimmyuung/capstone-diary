import logging
import json
import google.generativeai as genai
from django.conf import settings

logger = logging.getLogger(__name__)

# Global variable for singleton model
_SENTENCE_TRANSFORMER_MODEL = None

def get_sentence_transformer_model():
    """
    SentenceTransformer ëª¨ë¸ì„ ì‹±ê¸€í†¤ìœ¼ë¡œ ë¡œë“œí•˜ì—¬ ë°˜í™˜
    """
    global _SENTENCE_TRANSFORMER_MODEL
    if _SENTENCE_TRANSFORMER_MODEL is None:
        try:
            from sentence_transformers import SentenceTransformer
            logger.info("Loading SentenceTransformer model... (This should happen once per worker)")
            _SENTENCE_TRANSFORMER_MODEL = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        except ImportError:
            logger.warning("sentence-transformers not installed. Keyword extraction disabled.")
            _SENTENCE_TRANSFORMER_MODEL = None
        except Exception as e:
            logger.error(f"Failed to load SentenceTransformer model: {e}")
            _SENTENCE_TRANSFORMER_MODEL = None
            
    return _SENTENCE_TRANSFORMER_MODEL

class KeywordExtractor:
    """
    KeyBERT ë°©ì‹ì˜ í‚¤ì›Œë“œ ì¶”ì¶œê¸° (Singleton Model ì‚¬ìš©)
    - ë¬¸ì„œë¥¼ n-gramìœ¼ë¡œ ë¶„í• 
    - ë¬¸ì„œì™€ n-gramì˜ ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°
    - ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ í‚¤ì›Œë“œ(êµ¬) ì¶”ì¶œ
    """
    
    def __init__(self):
        # ìƒì„±ìì—ì„œëŠ” ëª¨ë¸ì„ ì§ì ‘ ë¡œë“œí•˜ì§€ ì•Šê³ , ë©”ì„œë“œ í˜¸ì¶œ ì‹œ get_model() ì‚¬ìš©
        pass

    def extract_keywords(self, text, top_n=5, keyphrase_ngram_range=(1, 2)):
        """
        í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ/êµ¬ ì¶”ì¶œ
        """
        model = get_sentence_transformer_model()
        
        if not model or not text or len(text) < 10:
            return []
            
        try:
            from sklearn.feature_extraction.text import CountVectorizer
            from sklearn.metrics.pairwise import cosine_similarity
            
            # 1. n-gram í›„ë³´ ìƒì„±
            count = CountVectorizer(ngram_range=keyphrase_ngram_range, stop_words=None).fit([text])
            candidates = count.get_feature_names_out()

            # 2. ë¬¸ì„œ ë° í›„ë³´ ì„ë² ë”©
            doc_embedding = model.encode([text])
            candidate_embeddings = model.encode(candidates)

            # 3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            distances = cosine_similarity(doc_embedding, candidate_embeddings)
            
            # 4. ìƒìœ„ nê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = []
            for index in distances.argsort()[0][-top_n:]:
                keywords.append(candidates[index])
            
            # ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (argsortëŠ” ì˜¤ë¦„ì°¨ìˆœì´ë¯€ë¡œ ë’¤ì§‘ìŒ)
            return keywords[::-1]
            
        except Exception as e:
            logger.error(f"Keyword extraction failed: {e}")
            return []


class NounExtractor:
    """
    [Option A] ì •í™•í•œ ë‹¨ì–´ ê²€ìƒ‰ì„ ìœ„í•œ ëª…ì‚¬ ì¶”ì¶œê¸°.
    Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³¸ë¬¸ì—ì„œ ëª…ì‚¬ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    (ì•”í˜¸í™”ëœ ë³¸ë¬¸ì„ ëŒ€ì²´í•  ê²€ìƒ‰ ì¸ë±ìŠ¤ ìš©ë„)
    """
    _kiwi = None
    
    @classmethod
    def _get_kiwi(cls):
        if cls._kiwi is None:
            try:
                from kiwipiepy import Kiwi
                cls._kiwi = Kiwi(model_type='sbg') # sbg: small model (faster)
                logger.info("Loaded Kiwi morphological analyzer.")
            except ImportError:
                logger.warning("kiwipiepy not installed. Noun extraction disabled.")
                cls._kiwi = None
            except Exception as e:
                logger.error(f"Failed to load Kiwi: {e}")
                cls._kiwi = None
        return cls._kiwi

    def extract_nouns(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ëª…ì‚¬(NNG, NNP, NR, NP)ë§Œ ì¶”ì¶œí•˜ì—¬ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ ë°˜í™˜.
        """
        if not text:
            return ""
            
        kiwi = self._get_kiwi()
        if not kiwi:
            return ""
            
        try:
            tokens = kiwi.tokenize(text)
            nouns = []
            for token in tokens:
                # NNG: ì¼ë°˜ëª…ì‚¬, NNP: ê³ ìœ ëª…ì‚¬, NR: ìˆ˜ì‚¬, NP: ëŒ€ëª…ì‚¬, SL: ì•ŒíŒŒë²³, SN: ìˆ«ì
                if token.tag in ['NNG', 'NNP', 'NR', 'NP', 'SL', 'SN']:
                    nouns.append(token.form)
            
            # ì¤‘ë³µ ì œê±° ë° ê³µë°± ì—°ê²°
            return ' '.join(list(set(nouns)))
            
        except Exception as e:
            logger.error(f"Noun extraction failed: {e}")
            return ""


class TemplateGenerator:
    """
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê¸° í…œí”Œë¦¿ì„ ìƒì„±í•˜ëŠ” ì„œë¹„ìŠ¤.
    ì‚¬ìš©ìê°€ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ ë§ì¶¤í˜• í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    def generate(self, topic: str, style: str = 'default') -> dict:
        """
        ì£¼ì œì— ë§ëŠ” ì¼ê¸° í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            topic: í…œí”Œë¦¿ ì£¼ì œ (ì˜ˆ: "ë…ì„œ ì¼ê¸°", "ìš”ë¦¬ ê¸°ë¡")
            style: ìŠ¤íƒ€ì¼ (default, simple, detailed)
            
        Returns:
            dict: {
                'name': í…œí”Œë¦¿ ì´ë¦„,
                'emoji': í…œí”Œë¦¿ ì•„ì´ì½˜,
                'description': í…œí”Œë¦¿ ì„¤ëª…,
                'content': í…œí”Œë¦¿ ë‚´ìš©
            }
        """
        logger.debug(f"Generating template for topic: {topic}, style: {style}")
        
        if not topic or len(topic.strip()) < 2:
            raise ValueError("ì£¼ì œë¥¼ 2ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        style_instruction = {
            'default': 'ì ë‹¹í•œ ê¸¸ì´ë¡œ ì‘ì„±í•˜ì„¸ìš”.',
            'simple': 'ê°„ë‹¨í•˜ê³  ì§§ê²Œ ì‘ì„±í•˜ì„¸ìš”. 3-4ê°œ í•­ëª©ë§Œ í¬í•¨í•˜ì„¸ìš”.',
            'detailed': 'ìì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ì–‘í•œ í•­ëª©ì„ í¬í•¨í•˜ì„¸ìš”.',
        }.get(style, 'ì ë‹¹í•œ ê¸¸ì´ë¡œ ì‘ì„±í•˜ì„¸ìš”.')
        
        try:
            model = genai.GenerativeModel(settings.GEMINI_TEXT_MODEL)
            
            prompt = f"""ë‹¹ì‹ ì€ ì¼ê¸° í…œí”Œë¦¿ì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì£¼ì œì— ë§ëŠ” ì¼ê¸° í…œí”Œë¦¿ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ì£¼ì œ: {topic}
ìš”êµ¬ì‚¬í•­: {style_instruction}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "name": "í…œí”Œë¦¿ ì´ë¦„ (ìµœëŒ€ 15ì)",
    "emoji": "ëŒ€í‘œ ì´ëª¨ì§€ 1ê°œ",
    "description": "í…œí”Œë¦¿ ì„¤ëª… (ìµœëŒ€ 50ì)",
    "content": "í…œí”Œë¦¿ ë‚´ìš© (ì¤„ë°”ê¿ˆ í¬í•¨)"
}}

í…œí”Œë¦¿ ë‚´ìš© ê·œì¹™:
- ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ê° ì„¹ì…˜ì„ êµ¬ë¶„í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ ì±„ìš¸ ë¶€ë¶„ì€ ë¹ˆ ì¤„ë¡œ ë‚¨ê²¨ë‘ì„¸ìš”
- í•­ëª©ì€ ì§ˆë¬¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”"""

            response = model.generate_content(prompt)
            content = response.text.strip()
            
            # JSON íŒŒì‹±
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if content.startswith('```'):
                content = content.split('```')[1]
                if content.startswith('json'):
                    content = content[4:]
            elif content.startswith('```json'): # Additional safe guard
                content = content[7:]

            content = content.strip()
            if content.endswith('```'):
                content = content[:-3].strip()
            
            result = json.loads(content)
            
            # ìœ íš¨ì„± ê²€ì‚¬
            required_keys = ['name', 'emoji', 'description', 'content']
            for key in required_keys:
                if key not in result:
                    raise ValueError(f"Missing key: {key}")
            
            logger.info(f"Template generated: {result['name']}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            # í´ë°±: ê¸°ë³¸ í…œí”Œë¦¿ ë°˜í™˜
            return {
                'name': topic[:15],
                'emoji': 'ğŸ“',
                'description': f'{topic} ì¼ê¸°ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤',
                'content': f'{topic}\n\nì˜¤ëŠ˜ì˜ ê¸°ë¡:\n\n\nëŠë‚€ ì :\n\n\në‚´ì¼ í•  ê²ƒ:\n'
            }
            
        except Exception as e:
            logger.error(f"Error generating template: {e}")
            raise e

    async def generate_async(self, topic: str, style: str = 'default') -> dict:
        """
        [Async] ì£¼ì œì— ë§ëŠ” ì¼ê¸° í…œí”Œë¦¿ì„ ë¹„ë™ê¸°ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        (Non-blocking I/O)
        """
        logger.debug(f"Generating template (async) for topic: {topic}, style: {style}")
        
        if not topic or len(topic.strip()) < 2:
            raise ValueError("ì£¼ì œë¥¼ 2ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        style_instruction = {
            'default': 'ì ë‹¹í•œ ê¸¸ì´ë¡œ ì‘ì„±í•˜ì„¸ìš”.',
            'simple': 'ê°„ë‹¨í•˜ê³  ì§§ê²Œ ì‘ì„±í•˜ì„¸ìš”. 3-4ê°œ í•­ëª©ë§Œ í¬í•¨í•˜ì„¸ìš”.',
            'detailed': 'ìì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ì–‘í•œ í•­ëª©ì„ í¬í•¨í•˜ì„¸ìš”.',
        }.get(style, 'ì ë‹¹í•œ ê¸¸ì´ë¡œ ì‘ì„±í•˜ì„¸ìš”.')
        
        try:
            model = genai.GenerativeModel(settings.GEMINI_TEXT_MODEL)
            
            prompt = f"""ë‹¹ì‹ ì€ ì¼ê¸° í…œí”Œë¦¿ì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì£¼ì œì— ë§ëŠ” ì¼ê¸° í…œí”Œë¦¿ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ì£¼ì œ: {topic}
ìš”êµ¬ì‚¬í•­: {style_instruction}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "name": "í…œí”Œë¦¿ ì´ë¦„ (ìµœëŒ€ 15ì)",
    "emoji": "ëŒ€í‘œ ì´ëª¨ì§€ 1ê°œ",
    "description": "í…œí”Œë¦¿ ì„¤ëª… (ìµœëŒ€ 50ì)",
    "content": "í…œí”Œë¦¿ ë‚´ìš© (ì¤„ë°”ê¿ˆ í¬í•¨)"
}}

í…œí”Œë¦¿ ë‚´ìš© ê·œì¹™:
- ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ê° ì„¹ì…˜ì„ êµ¬ë¶„í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ ì±„ìš¸ ë¶€ë¶„ì€ ë¹ˆ ì¤„ë¡œ ë‚¨ê²¨ë‘ì„¸ìš”
- í•­ëª©ì€ ì§ˆë¬¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”"""

            # Async call to Gemini
            response = await model.generate_content_async(prompt)
            content = response.text.strip()
            
            # JSON íŒŒì‹± ë¡œì§ ì¬ì‚¬ìš©
            if content.startswith('```'):
                content = content.split('```')[1]
                if content.startswith('json'):
                    content = content[4:]
            elif content.startswith('```json'): # Additional safe guard
                content = content[7:]

            content = content.strip()
            if content.endswith('```'):
                content = content[:-3].strip()
            
            result = json.loads(content)
            
            # ìœ íš¨ì„± ê²€ì‚¬
            required_keys = ['name', 'emoji', 'description', 'content']
            for key in required_keys:
                if key not in result:
                    raise ValueError(f"Missing key: {key}")
            
            logger.info(f"Template generated (async): {result['name']}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            return {
                'name': topic[:15],
                'emoji': 'ğŸ“',
                'description': f'{topic} ì¼ê¸°ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤',
                'content': f'{topic}\n\nì˜¤ëŠ˜ì˜ ê¸°ë¡:\n\n\nëŠë‚€ ì :\n\n\në‚´ì¼ í•  ê²ƒ:\n'
            }
            
        except Exception as e:
            logger.error(f"Error generating template (async): {e}")
            raise e

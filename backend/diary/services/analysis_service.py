import logging
import json
from google import genai
from django.conf import settings

logger = logging.getLogger(__name__)

# Global variable for singleton model
_SENTENCE_TRANSFORMER_MODEL = None

def get_sentence_transformer_model():
    """
    SentenceTransformer ëª¨ë¸ì„ ì‹±ê¸€í†¤ìœ¼ë¡œ ë¡œë“œí•˜ì—¬ ë°˜í™˜
    """
    global _SENTENCE_TRANSFORMER_MODEL
    if _SENTENCE_TRANSFORMER_MODEL is None:
        try:
            from sentence_transformers import SentenceTransformer
            logger.info("Loading SentenceTransformer model... (This should happen once per worker)")
            _SENTENCE_TRANSFORMER_MODEL = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        except ImportError:
            logger.warning("sentence-transformers not installed. Keyword extraction disabled.")
            _SENTENCE_TRANSFORMER_MODEL = None
        except Exception as e:
            logger.error(f"Failed to load SentenceTransformer model: {e}")
            _SENTENCE_TRANSFORMER_MODEL = None
            
    return _SENTENCE_TRANSFORMER_MODEL

class KeywordExtractor:
    """
    KeyBERT ë°©ì‹ì˜ í‚¤ì›Œë“œ ì¶”ì¶œê¸° (Singleton Model ì‚¬ìš©)
    - ë¬¸ì„œë¥¼ n-gramìœ¼ë¡œ ë¶„í• 
    - ë¬¸ì„œì™€ n-gramì˜ ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°
    - ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ í‚¤ì›Œë“œ(êµ¬) ì¶”ì¶œ
    """
    
    def __init__(self):
        # ìƒì„±ìì—ì„œëŠ” ëª¨ë¸ì„ ì§ì ‘ ë¡œë“œí•˜ì§€ ì•Šê³ , ë©”ì„œë“œ í˜¸ì¶œ ì‹œ get_model() ì‚¬ìš©
        pass

    def extract_keywords(self, text, top_n=5, keyphrase_ngram_range=(1, 2)):
        """
        í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ/êµ¬ ì¶”ì¶œ
        """
        model = get_sentence_transformer_model()
        
        if not model or not text or len(text) < 10:
            return []
            
        try:
            from sklearn.feature_extraction.text import CountVectorizer
            from sklearn.metrics.pairwise import cosine_similarity
            
            # 1. n-gram í›„ë³´ ìƒì„±
            count = CountVectorizer(ngram_range=keyphrase_ngram_range, stop_words=None).fit([text])
            candidates = count.get_feature_names_out()

            # 2. ë¬¸ì„œ ë° í›„ë³´ ì„ë² ë”©
            doc_embedding = model.encode([text])
            candidate_embeddings = model.encode(candidates)

            # 3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            distances = cosine_similarity(doc_embedding, candidate_embeddings)
            
            # 4. ìƒìœ„ nê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = []
            for index in distances.argsort()[0][-top_n:]:
                keywords.append(candidates[index])
            
            # ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (argsortëŠ” ì˜¤ë¦„ì°¨ìˆœì´ë¯€ë¡œ ë’¤ì§‘ìŒ)
            return keywords[::-1]
            
        except Exception as e:
            logger.error(f"Keyword extraction failed: {e}")
            return []


class NounExtractor:
    """
    [Option A] ì •í™•í•œ ë‹¨ì–´ ê²€ìƒ‰ì„ ìœ„í•œ ëª…ì‚¬ ì¶”ì¶œê¸°.
    Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³¸ë¬¸ì—ì„œ ëª…ì‚¬ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    (ì•”í˜¸í™”ëœ ë³¸ë¬¸ì„ ëŒ€ì²´í•  ê²€ìƒ‰ ì¸ë±ìŠ¤ ìš©ë„)
    """
    _kiwi = None
    
    @classmethod
    def _get_kiwi(cls):
        if cls._kiwi is None:
            try:
                from kiwipiepy import Kiwi
                cls._kiwi = Kiwi(model_type='sbg') # sbg: small model (faster)
                logger.info("Loaded Kiwi morphological analyzer.")
            except ImportError:
                logger.warning("kiwipiepy not installed. Noun extraction disabled.")
                cls._kiwi = None
            except Exception as e:
                logger.error(f"Failed to load Kiwi: {e}")
                cls._kiwi = None
        return cls._kiwi

    def extract_nouns(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ëª…ì‚¬(NNG, NNP, NR, NP)ë§Œ ì¶”ì¶œí•˜ì—¬ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ ë°˜í™˜.
        """
        if not text:
            return ""
            
        kiwi = self._get_kiwi()
        if not kiwi:
            return ""
            
        try:
            tokens = kiwi.tokenize(text)
            nouns = []
            for token in tokens:
                # NNG: ì¼ë°˜ëª…ì‚¬, NNP: ê³ ìœ ëª…ì‚¬, NR: ìˆ˜ì‚¬, NP: ëŒ€ëª…ì‚¬, SL: ì•ŒíŒŒë²³, SN: ìˆ«ì
                if token.tag in ['NNG', 'NNP', 'NR', 'NP', 'SL', 'SN']:
                    nouns.append(token.form)
            
            # ì¤‘ë³µ ì œê±° ë° ê³µë°± ì—°ê²°
            return ' '.join(list(set(nouns)))
            
        except Exception as e:
            logger.error(f"Noun extraction failed: {e}")
            return ""


class TemplateGenerator:
    """
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê¸° í…œí”Œë¦¿ì„ ìƒì„±í•˜ëŠ” ì„œë¹„ìŠ¤.
    ì‚¬ìš©ìê°€ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ ë§ì¶¤í˜• í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    from ..utils.retry_utils import ai_retry_policy

    @ai_retry_policy
    def _call_gemini(self, client, model, prompt):
        """Gemini API í˜¸ì¶œ (ì¬ì‹œë„ ì ìš©)"""
        return client.models.generate_content(
            model=model,
            contents=prompt
        )

    
    def generate(self, topic: str, style: str = 'default') -> dict:
        """
        ì£¼ì œì— ë§ëŠ” ì¼ê¸° í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            topic: í…œí”Œë¦¿ ì£¼ì œ (ì˜ˆ: "ë…ì„œ ì¼ê¸°", "ìš”ë¦¬ ê¸°ë¡")
            style: ìŠ¤íƒ€ì¼ (default, simple, detailed)
            
        Returns:
            dict: {
                'name': í…œí”Œë¦¿ ì´ë¦„,
                'emoji': í…œí”Œë¦¿ ì•„ì´ì½˜,
                'description': í…œí”Œë¦¿ ì„¤ëª…,
                'content': í…œí”Œë¦¿ ë‚´ìš©
            }
        """
        logger.debug(f"Generating template for topic: {topic}, style: {style}")
        
        if not topic or len(topic.strip()) < 2:
            raise ValueError("ì£¼ì œë¥¼ 2ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        style_instruction = {
            'default': 'ì ë‹¹í•œ ê¸¸ì´ë¡œ ì‘ì„±í•˜ì„¸ìš”.',
            'simple': 'ê°„ë‹¨í•˜ê³  ì§§ê²Œ ì‘ì„±í•˜ì„¸ìš”. 3-4ê°œ í•­ëª©ë§Œ í¬í•¨í•˜ì„¸ìš”.',
            'detailed': 'ìì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ì–‘í•œ í•­ëª©ì„ í¬í•¨í•˜ì„¸ìš”.',
        }.get(style, 'ì ë‹¹í•œ ê¸¸ì´ë¡œ ì‘ì„±í•˜ì„¸ìš”.')
        
        try:
            client = genai.Client(api_key=settings.GEMINI_API_KEY)
            
            prompt = f"""ë‹¹ì‹ ì€ ì¼ê¸° í…œí”Œë¦¿ì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì£¼ì œì— ë§ëŠ” ì¼ê¸° í…œí”Œë¦¿ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ì£¼ì œ: {topic}
ìš”êµ¬ì‚¬í•­: {style_instruction}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "name": "í…œí”Œë¦¿ ì´ë¦„ (ìµœëŒ€ 15ì)",
    "emoji": "ëŒ€í‘œ ì´ëª¨ì§€ 1ê°œ",
    "description": "í…œí”Œë¦¿ ì„¤ëª… (ìµœëŒ€ 50ì)",
    "content": "í…œí”Œë¦¿ ë‚´ìš© (ì¤„ë°”ê¿ˆ í¬í•¨)"
}}

í…œí”Œë¦¿ ë‚´ìš© ê·œì¹™:
- ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ê° ì„¹ì…˜ì„ êµ¬ë¶„í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ ì±„ìš¸ ë¶€ë¶„ì€ ë¹ˆ ì¤„ë¡œ ë‚¨ê²¨ë‘ì„¸ìš”
- í•­ëª©ì€ ì§ˆë¬¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”"""

            # API í˜¸ì¶œ (Retry ì ìš©)
            response = self._call_gemini(client, settings.GEMINI_TEXT_MODEL, prompt)
            content = response.text.strip()
            
            # JSON íŒŒì‹±
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if content.startswith('```'):
                content = content.split('```')[1]
                if content.startswith('json'):
                    content = content[4:]
            elif content.startswith('```json'): # Additional safe guard
                content = content[7:]

            content = content.strip()
            if content.endswith('```'):
                content = content[:-3].strip()
            
            result = json.loads(content)
            
            # ìœ íš¨ì„± ê²€ì‚¬
            required_keys = ['name', 'emoji', 'description', 'content']
            for key in required_keys:
                if key not in result:
                    raise ValueError(f"Missing key: {key}")
            
            logger.info(f"Template generated: {result['name']}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            # í´ë°±: ê¸°ë³¸ í…œí”Œë¦¿ ë°˜í™˜
            return {
                'name': topic[:15],
                'emoji': 'ğŸ“',
                'description': f'{topic} ì¼ê¸°ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤',
                'content': f'{topic}\n\nì˜¤ëŠ˜ì˜ ê¸°ë¡:\n\n\nëŠë‚€ ì :\n\n\në‚´ì¼ í•  ê²ƒ:\n'
            }
            
        except Exception as e:
            logger.error(f"Error generating template: {e}")
            raise e

    async def generate_async(self, topic: str, style: str = 'default') -> dict:
        """
        [Async] ì£¼ì œì— ë§ëŠ” ì¼ê¸° í…œí”Œë¦¿ì„ ë¹„ë™ê¸°ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        (Non-blocking I/O)
        """
        logger.debug(f"Generating template (async) for topic: {topic}, style: {style}")
        
        if not topic or len(topic.strip()) < 2:
            raise ValueError("ì£¼ì œë¥¼ 2ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        style_instruction = {
            'default': 'ì ë‹¹í•œ ê¸¸ì´ë¡œ ì‘ì„±í•˜ì„¸ìš”.',
            'simple': 'ê°„ë‹¨í•˜ê³  ì§§ê²Œ ì‘ì„±í•˜ì„¸ìš”. 3-4ê°œ í•­ëª©ë§Œ í¬í•¨í•˜ì„¸ìš”.',
            'detailed': 'ìì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ì–‘í•œ í•­ëª©ì„ í¬í•¨í•˜ì„¸ìš”.',
        }.get(style, 'ì ë‹¹í•œ ê¸¸ì´ë¡œ ì‘ì„±í•˜ì„¸ìš”.')
        
        try:
            client = genai.Client(api_key=settings.GEMINI_API_KEY)
            
            prompt = f"""ë‹¹ì‹ ì€ ì¼ê¸° í…œí”Œë¦¿ì„ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì£¼ì œì— ë§ëŠ” ì¼ê¸° í…œí”Œë¦¿ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ì£¼ì œ: {topic}
ìš”êµ¬ì‚¬í•­: {style_instruction}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "name": "í…œí”Œë¦¿ ì´ë¦„ (ìµœëŒ€ 15ì)",
    "emoji": "ëŒ€í‘œ ì´ëª¨ì§€ 1ê°œ",
    "description": "í…œí”Œë¦¿ ì„¤ëª… (ìµœëŒ€ 50ì)",
    "content": "í…œí”Œë¦¿ ë‚´ìš© (ì¤„ë°”ê¿ˆ í¬í•¨)"
}}

í…œí”Œë¦¿ ë‚´ìš© ê·œì¹™:
- ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ê° ì„¹ì…˜ì„ êµ¬ë¶„í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ ì±„ìš¸ ë¶€ë¶„ì€ ë¹ˆ ì¤„ë¡œ ë‚¨ê²¨ë‘ì„¸ìš”
- í•­ëª©ì€ ì§ˆë¬¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”"""

            # Async call (Retry ì ìš©)
            response = self._call_gemini(client, settings.GEMINI_TEXT_MODEL, prompt)
            content = response.text.strip()
            
            # JSON íŒŒì‹± ë¡œì§ ì¬ì‚¬ìš©
            if content.startswith('```'):
                content = content.split('```')[1]
                if content.startswith('json'):
                    content = content[4:]
            elif content.startswith('```json'): # Additional safe guard
                content = content[7:]

            content = content.strip()
            if content.endswith('```'):
                content = content[:-3].strip()
            
            result = json.loads(content)
            
            # ìœ íš¨ì„± ê²€ì‚¬
            required_keys = ['name', 'emoji', 'description', 'content']
            for key in required_keys:
                if key not in result:
                    raise ValueError(f"Missing key: {key}")
            
            logger.info(f"Template generated (async): {result['name']}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            return {
                'name': topic[:15],
                'emoji': 'ğŸ“',
                'description': f'{topic} ì¼ê¸°ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤',
                'content': f'{topic}\n\nì˜¤ëŠ˜ì˜ ê¸°ë¡:\n\n\nëŠë‚€ ì :\n\n\në‚´ì¼ í•  ê²ƒ:\n'
            }
            
        except Exception as e:
            logger.error(f"Error generating template (async): {e}")
            raise e


class EmotionTrendAnalyzer:
    """
    ê°ì • íŠ¸ë Œë“œ ë¶„ì„ê¸°
    - ì—°ì† ë¶€ì •ì  ê°ì • ê°ì§€
    - ì£¼ê°„ ê°ì • íŠ¸ë Œë“œ ë¶„ì„
    - ë§ì¶¤ ê²©ë ¤ ë©”ì‹œì§€ ìƒì„±
    """
    
    NEGATIVE_EMOTIONS = {'sad', 'angry', 'anxious', 'tired'}
    POSITIVE_EMOTIONS = {'happy', 'peaceful', 'excited', 'love'}
    
    ENCOURAGEMENT_MESSAGES = {
        'sad': [
            "í˜ë“  ì‹œê°„ì„ ë³´ë‚´ê³  ê³„ì‹œë„¤ìš”. ê´œì°®ì•„ìš”, ì´ ë˜í•œ ì§€ë‚˜ê°ˆ ê±°ì˜ˆìš”. ğŸŒˆ",
            "ìŠ¬í””ì„ ëŠë¼ëŠ” ê²ƒë„ ìì—°ìŠ¤ëŸ¬ìš´ ê°ì •ì´ì—ìš”. ìŠ¤ìŠ¤ë¡œë¥¼ ëŒë³´ëŠ” ì‹œê°„ì„ ê°€ì ¸ë³´ì„¸ìš”. ğŸ’™",
        ],
        'angry': [
            "í™”ê°€ ë‚˜ëŠ” ê°ì •ì´ ê³„ì†ë˜ê³  ìˆë„¤ìš”. ê¹Šê²Œ ìˆ¨ì„ ì‰¬ì–´ë³´ì„¸ìš”. ğŸŒ¿",
            "ë¶„ë…¸ ë’¤ì— ìˆ¨ê²¨ì§„ ì§„ì§œ ê°ì •ì„ ì°¾ì•„ë³´ë©´ ì–´ë–¨ê¹Œìš”? ğŸ’­",
        ],
        'anxious': [
            "ë¶ˆì•ˆí•œ ë‚˜ë‚ ì´ ì´ì–´ì§€ê³  ìˆêµ°ìš”. ì˜¤ëŠ˜ í•˜ë£¨ ì‘ì€ ê²ƒì— ì§‘ì¤‘í•´ë³´ì„¸ìš”. â˜ï¸",
            "ë¶ˆì•ˆí•¨ì„ ëŠë¼ëŠ” ê±´ ë³€í™”ë¥¼ ì›í•œë‹¤ëŠ” ì‹ í˜¸ì¼ ìˆ˜ë„ ìˆì–´ìš”. ğŸŒ±",
        ],
        'tired': [
            "í”¼ê³¤í•¨ì´ ìŒ“ì´ê³  ìˆë„¤ìš”. ì¶©ë¶„í•œ íœ´ì‹ì„ ì·¨í•˜ì…¨ë‚˜ìš”? ğŸ˜´",
            "ì§€ì¹œ ë§ˆìŒì—ê²Œ ì‰¬ì–´ê°ˆ ì‹œê°„ì„ ì£¼ì„¸ìš”. ì‘ì€ ì‚°ì±…ë„ ë„ì›€ì´ ë  ê±°ì˜ˆìš”. ğŸš¶",
        ],
    }
    
    @classmethod
    def analyze_recent_trend(cls, user, days: int = 7) -> dict:
        """
        ìµœê·¼ Nì¼ê°„ì˜ ê°ì • íŠ¸ë Œë“œ ë¶„ì„
        
        Returns:
            {
                'consecutive_negative': int,  # ì—°ì† ë¶€ì •ì  ê°ì • ì¼ìˆ˜
                'needs_alert': bool,          # ì•Œë¦¼ í•„ìš” ì—¬ë¶€ (3ì¼ ì´ìƒ ì—°ì†)
                'dominant_negative': str,     # ê°€ì¥ ë§ì´ ê¸°ë¡ëœ ë¶€ì • ê°ì •
                'message': str,               # ê²©ë ¤ ë©”ì‹œì§€ (ì•Œë¦¼ í•„ìš”ì‹œ)
                'positive_ratio': float,      # ê¸ì • ê°ì • ë¹„ìœ¨
                'total_entries': int,         # ì´ ì¼ê¸° ìˆ˜
            }
        """
        from datetime import date, timedelta
        from ..models import Diary
        
        end_date = date.today()
        start_date = end_date - timedelta(days=days)
        
        diaries = Diary.objects.filter(
            user=user,
            created_at__date__gte=start_date,
            created_at__date__lte=end_date,
            emotion__isnull=False
        ).order_by('-created_at')
        
        if not diaries.exists():
            return {
                'consecutive_negative': 0,
                'needs_alert': False,
                'dominant_negative': None,
                'message': None,
                'positive_ratio': 0.0,
                'total_entries': 0,
            }
        
        emotions = [d.emotion for d in diaries]
        total_entries = len(emotions)
        
        # ì—°ì† ë¶€ì •ì  ê°ì • ê³„ì‚°
        consecutive_negative = 0
        for emotion in emotions:
            if emotion in cls.NEGATIVE_EMOTIONS:
                consecutive_negative += 1
            else:
                break  # ì—°ì†ì´ ëŠê¸°ë©´ ì¤‘ë‹¨
        
        # ìš°ì„¸ ë¶€ì • ê°ì • ê³„ì‚°
        negative_counts = {}
        positive_count = 0
        for emotion in emotions:
            if emotion in cls.NEGATIVE_EMOTIONS:
                negative_counts[emotion] = negative_counts.get(emotion, 0) + 1
            elif emotion in cls.POSITIVE_EMOTIONS:
                positive_count += 1
        
        dominant_negative = max(negative_counts, key=negative_counts.get) if negative_counts else None
        positive_ratio = positive_count / total_entries if total_entries > 0 else 0.0
        
        # ì•Œë¦¼ í•„ìš” ì—¬ë¶€ (3ì¼ ì—°ì† ë¶€ì • ê°ì •)
        needs_alert = consecutive_negative >= 3
        
        # ê²©ë ¤ ë©”ì‹œì§€ ì„ íƒ
        message = None
        if needs_alert and dominant_negative:
            import random
            messages = cls.ENCOURAGEMENT_MESSAGES.get(dominant_negative, [])
            if messages:
                message = random.choice(messages)
        
        return {
            'consecutive_negative': consecutive_negative,
            'needs_alert': needs_alert,
            'dominant_negative': dominant_negative,
            'message': message,
            'positive_ratio': round(positive_ratio, 2),
            'total_entries': total_entries,
        }
    
    @classmethod
    def get_weekly_summary(cls, user) -> dict:
        """
        ì£¼ê°„ ê°ì • ìš”ì•½ (ì‹œê°„ëŒ€ë³„/ìš”ì¼ë³„ í†µê³„ í¬í•¨)
        """
        from datetime import date, timedelta
        from collections import defaultdict
        from ..models import Diary
        
        end_date = date.today()
        start_date = end_date - timedelta(days=7)
        
        diaries = Diary.objects.filter(
            user=user,
            created_at__date__gte=start_date,
            created_at__date__lte=end_date
        )
        
        # ìš”ì¼ë³„ ê°ì • ë¶„í¬
        weekday_emotions = defaultdict(list)
        # ì‹œê°„ëŒ€ë³„ ê°ì • ë¶„í¬ (0-6: ìƒˆë²½, 6-12: ì•„ì¹¨, 12-18: ì˜¤í›„, 18-24: ì €ë…)
        hour_emotions = defaultdict(list)
        
        WEEKDAY_NAMES = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        HOUR_RANGES = {
            (0, 6): 'ìƒˆë²½',
            (6, 12): 'ì•„ì¹¨',
            (12, 18): 'ì˜¤í›„',
            (18, 24): 'ì €ë…',
        }
        
        for diary in diaries:
            if diary.emotion:
                weekday = diary.created_at.weekday()
                weekday_emotions[WEEKDAY_NAMES[weekday]].append(diary.emotion)
                
                hour = diary.created_at.hour
                for (start, end), name in HOUR_RANGES.items():
                    if start <= hour < end:
                        hour_emotions[name].append(diary.emotion)
                        break
        
        # ê° ê·¸ë£¹ë³„ ìš°ì„¸ ê°ì • ê³„ì‚°
        def get_dominant(emotions_list):
            if not emotions_list:
                return None
            from collections import Counter
            return Counter(emotions_list).most_common(1)[0][0]
        
        return {
            'weekday_patterns': {day: get_dominant(emotions) for day, emotions in weekday_emotions.items()},
            'hourly_patterns': {period: get_dominant(emotions) for period, emotions in hour_emotions.items()},
            'total_diaries': diaries.count(),
        }
